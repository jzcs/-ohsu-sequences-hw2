{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW4\n",
    "\n",
    "\n",
    "## VQ and EM  algorithm\n",
    "\n",
    "This homework we'll be focusing on EM Algorithm on a very simple coin tossing example. The goal of the homework is to estimate the parameters of the model given training examples. The homework is based on the following paper and you are highly encouraged to read through the paper to fully understand the problem:\n",
    "\n",
    "* Do, Chuong B., and Serafim Batzoglou. \"What is the expectation maximization algorithm?.\" Nature biotechnology 26.8 (2008): 897-899.\n",
    "\n",
    "The observed features are sequences of twenty heads (H) and tails (T) coming from three unfair coins as follow stored at `seq_H_T.txt`. We generate these samples with three different coins. We also offer you the code for sample generation.\n",
    "\n",
    "     \n",
    "### Part 1 - Vector quantization\n",
    "Given the sample sequences of three coins, estimate the biases (centers) using VQ (k-means) algorithm. For implementing k-means, you can randomly initialize three centers from the range of 0 to 1. This mean we will group samples based on their frequency of heads. For example, let's say we have two centers, 0.2 and 0.9, and a sample, frequency of heads is 0.7. Then, this sample would be consider belongs to the second group. \n",
    "\n",
    "Also since we already know that there are only three coins, we fix the total number of centers to 3.\n",
    "\n",
    "\n",
    "#### What to turn in:\n",
    "\n",
    "1. Submit your estimated biases at the end of 25th itration of both VQ and EM along with your codes. \n",
    "    2. Check how quickly parameters of the model (biases in this example) converge by drawing  parametrs in a plot where the X axis is the number of iteration and Y axis is the estimated biased values. It should looks like this ![](VQ.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red> self-assessment: </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2 - EM\n",
    "Estimate the biases via EM given the sample sequences. Please check [this slide](https://repo.cslu.ohsu.edu/asgari/seqf18/blob/master/Lectures/lect1_week7.pdf) for how to implement it.\n",
    "\n",
    "\n",
    "#### For Part 2 only:\n",
    "* Submit your estimated biases at the end of 25th itration of both VQ and EM along with your codes. \n",
    "2. Check how quickly parameters of the model (biases in this example) converge by drawing  parametrs in a plot where the X axis is the number of iteration and Y axis is the estimated biased values. It should looks like this ![](em_theta.png)\n",
    "3. Monitor the learning progress by drawing the log-likelihood score in a plot where the horizontal axis is the number of iteration. \n",
    "$$\\textbf{X}=\\{X_1,\\cdots,X_N\\} ~~;~~ \\Theta=\\{\\theta_1,\\theta_2,\\theta_3\\}$$ \n",
    "$$L(\\Theta|\\textbf{X})=\\sum_{i=1}^N{\\log\\sum_{k=1}^3{\\pi_k p(X_i|\\theta_k)}}$$\n",
    "\n",
    "4. Try out a few different initial probabilities and discuss its effect on the estimated parameters. \n",
    "5. Try out the estimated parameters obtained by VQ as initiale points to EM and discuss its benefits\n",
    "\n",
    "## Reminder\n",
    "\n",
    "\n",
    "For the HW, you are allowed to use python libraries such as numpy. However, you should write your own code from the scratch; i.e., you are not allowed to use built-in functions for VQ and EM  algorithms such as those that are available at scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red> self-assessment: </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
